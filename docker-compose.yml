services:
  # PostgreSQL 18 (Local Database)
  postgres:
    image: postgres:18-alpine
    container_name: whisper_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-whisper_summarizer}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - whisper_network
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # FastAPIバックエンド (faster-whisper + Supabase Auth + Local PostgreSQL)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    image: whisper-summarizer-backend:latest
    container_name: whisper_backend
    environment:
      # Database (Local PostgreSQL)
      DATABASE_URL: postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-whisper_summarizer}

      # Supabase
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY}

      # GLM API (OpenAI-compatible)
      GLM_API_KEY: ${GLM_API_KEY}
      GLM_MODEL: ${GLM_MODEL:-GLM-4.5-Air}
      GLM_BASE_URL: ${GLM_BASE_URL:-https://api.z.ai/api/paas/v4/}
      REVIEW_LANGUAGE: ${REVIEW_LANGUAGE:-zh}

      # Backend Config
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}
      SECRET_KEY: ${SECRET_KEY:-your-secret-key-change-in-production}

      # faster-whisper Config (GPU-accelerated transcription)
      FASTER_WHISPER_DEVICE: ${FASTER_WHISPER_DEVICE:-cuda}
      FASTER_WHISPER_COMPUTE_TYPE: ${FASTER_WHISPER_COMPUTE_TYPE:-int8_float16}
      FASTER_WHISPER_MODEL_SIZE: ${FASTER_WHISPER_MODEL_SIZE:-large-v3-turbo}
      WHISPER_LANGUAGE: ${WHISPER_LANGUAGE:-ja}
      WHISPER_THREADS: ${WHISPER_THREADS:-4}

      # Audio Processing
      AUDIO_PARALLELISM: ${AUDIO_PARALLELISM:-1}

      # Audio Chunking (for faster transcription of long audio)
      ENABLE_CHUNKING: ${ENABLE_CHUNKING:-true}
      CHUNK_SIZE_MINUTES: ${CHUNK_SIZE_MINUTES:-10}
      CHUNK_OVERLAP_SECONDS: ${CHUNK_OVERLAP_SECONDS:-15}
      MAX_CONCURRENT_CHUNKS: ${MAX_CONCURRENT_CHUNKS:-2}
      USE_VAD_SPLIT: ${USE_VAD_SPLIT:-false}
      VAD_SILENCE_THRESHOLD: ${VAD_SILENCE_THRESHOLD:--30}
      VAD_MIN_SILENCE_DURATION: ${VAD_MIN_SILENCE_DURATION:-0.5}
      MERGE_STRATEGY: ${MERGE_STRATEGY:-lcs}

      # Testing
      DISABLE_AUTH: ${DISABLE_AUTH:-false}

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    volumes:
      - backend_data:/app/data
      - backend_output:/app/output
    # GPU Support (faster-whisper with cuDNN)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    networks:
      - whisper_network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Reactフロントエンド (本番モード - Nginx)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: production
      args:
        VITE_SUPABASE_URL: ${SUPABASE_URL}
        VITE_SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
    image: whisper-summarizer-frontend:latest
    container_name: whisper_frontend
    ports:
      - "${FRONTEND_PORT:-80}:80"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - whisper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  backend_data:
    driver: local
  backend_output:
    driver: local

networks:
  whisper_network:
    driver: bridge
