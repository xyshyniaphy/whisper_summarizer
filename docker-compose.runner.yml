services:
  # GPU Runner (uses runner/.env for configuration)
  runner:
    build:
      context: ./runner
      dockerfile: Dockerfile
    container_name: whisper_runner
    env_file:
      - ./runner/.env
    volumes:
      # Data directory mount (runner-specific storage)
      - ${DATA_DIR:-./data/runner}:/app/data
      # Logs directory
      - ${LOG_DIR:-./logs}:/app/logs
      # Whisper model cache
      - runner_cache:/tmp/whisper_models
    # GPU Support (faster-whisper with cuDNN)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "pgrep", "-f", "python.*poller"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 30s

volumes:
  runner_cache:
    driver: local
