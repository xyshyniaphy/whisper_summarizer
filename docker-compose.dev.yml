services:
  # PostgreSQL 18 Database (Alpine - Local Development)
  postgres:
    image: postgres:18-alpine
    container_name: whisper_postgres_dev
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-whisper_summarizer}
    volumes:
      - postgres_data_dev:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - whisper_network_dev

  # FastAPIバックエンド (開発モード - ホットリロード + faster-whisper + Local PostgreSQL)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: whisper_backend_dev
    environment:
      # Database (Local PostgreSQL)
      DATABASE_URL: postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-whisper_summarizer}

      # Supabase
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY}

      # GLM API (OpenAI-compatible)
      GLM_API_KEY: ${GLM_API_KEY}
      GLM_MODEL: ${GLM_MODEL:-GLM-4.5-Air}
      GLM_BASE_URL: ${GLM_BASE_URL:-https://api.z.ai/api/paas/v4/}
      REVIEW_LANGUAGE: ${REVIEW_LANGUAGE:-zh}

      # Backend Config
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}
      LOG_LEVEL: ${LOG_LEVEL:-DEBUG}
      DISABLE_AUTH: ${DISABLE_AUTH:-false}

      # faster-whisper Config (GPU-accelerated transcription)
      FASTER_WHISPER_DEVICE: ${FASTER_WHISPER_DEVICE:-cuda}
      FASTER_WHISPER_COMPUTE_TYPE: ${FASTER_WHISPER_COMPUTE_TYPE:-float16}
      FASTER_WHISPER_MODEL_SIZE: ${FASTER_WHISPER_MODEL_SIZE:-large-v3-turbo}
      WHISPER_LANGUAGE: ${WHISPER_LANGUAGE:-zh}
      WHISPER_THREADS: ${WHISPER_THREADS:-4}

      # Audio Chunking
      ENABLE_CHUNKING: ${ENABLE_CHUNKING:-true}
      CHUNK_SIZE_MINUTES: ${CHUNK_SIZE_MINUTES:-10}
      CHUNK_OVERLAP_SECONDS: ${CHUNK_OVERLAP_SECONDS:-15}
      MAX_CONCURRENT_CHUNKS: ${MAX_CONCURRENT_CHUNKS:-2}
      USE_VAD_SPLIT: ${USE_VAD_SPLIT:-false}
      VAD_SILENCE_THRESHOLD: ${VAD_SILENCE_THRESHOLD:--30}
      VAD_MIN_SILENCE_DURATION: ${VAD_MIN_SILENCE_DURATION:-0.5}
      MERGE_STRATEGY: ${MERGE_STRATEGY:-lcs}

      # Audio Processing
      AUDIO_PARALLELISM: ${AUDIO_PARALLELISM:-1}
    ports:
      - "5678:5678"  # デバッグポート
    volumes:
      # ソースコードをマウント (ホットリロード用)
      - ./backend:/app
      # ログディレクトリをマウント
      - ./logs:/app/logs
      # データディレクトリをマウント
      - ./data:/app/data
      # Pythonキャッシュを除外
      - /app/__pycache__
      - /app/.pytest_cache
      # venvは除外 (ビルド時に作成されたものを使用)
      - /opt/venv
    # GPU Support (faster-whisper with cuDNN)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    command: /bin/sh -c "uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --log-level debug 2>&1 | tee /app/logs/backend.log"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - whisper_network_dev

  # Reactフロントエンド (開発モード - Vite Dev Server)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    container_name: whisper_frontend_dev
    environment:
      VITE_SUPABASE_URL: ${SUPABASE_URL}
      VITE_SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      VITE_BACKEND_URL: ${VITE_BACKEND_URL:-http://localhost:3080}
    ports:
      - "3000:3000"
    volumes:
      # ソースコードをマウント (ホットリロード用)
      - ./frontend:/app
      # ログディレクトリをマウント
      - ./logs:/app/logs
      # node_modulesを除外
      - /app/node_modules
      # Viteキャッシュを除外
      - /app/.vite
    command: /bin/sh -c "npm run dev -- --host 0.0.0.0 2>&1 | tee /app/logs/frontend.log"
    depends_on:
      - backend
    networks:
      - whisper_network_dev

networks:
  whisper_network_dev:
    driver: bridge

volumes:
  postgres_data_dev:
    driver: local
