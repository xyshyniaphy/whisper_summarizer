# Production Docker Compose Configuration
# Optimized for production deployment with Cloudflare Tunnel

services:
  # PostgreSQL 18 Database
  postgres:
    image: postgres:18-alpine
    container_name: whisper_postgres_prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - whisper_network_prod
    restart: unless-stopped

  # Nginx Reverse Proxy (Single Entry Point)
  nginx:
    image: nginx:alpine
    container_name: whisper_nginx_prod
    ports:
      - "${NGINX_PORT:-8130}:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - server
      - frontend
    networks:
      - whisper_network_prod
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # FastAPI Server (Production)
  server:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: whisper_server_prod
    environment:
      DATABASE_URL: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      SUPABASE_URL: ${SUPABASE_URL}
      SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY}
      RUNNER_API_KEY: ${RUNNER_API_KEY}
      CORS_ORIGINS: ${CORS_ORIGINS}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      TRUSTED_HOSTS: ${TRUSTED_HOSTS:-nginx}
    volumes:
      - ./data/server:/app/data
      - ./data/uploads:/app/data/uploads
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - whisper_network_prod
    restart: unless-stopped

  # GPU Runner (Production - Optional, separate deployment)
  # Uncomment if running runner on same server
  # runner:
  #   build:
  #     context: ./runner
  #     dockerfile: Dockerfile
  #   container_name: whisper_runner_prod
  #   environment:
  #     SERVER_URL: http://server:8000
  #     RUNNER_API_KEY: ${RUNNER_API_KEY}
  #     RUNNER_ID: runner-prod-01
  #     GLM_API_KEY: ${GLM_API_KEY}
  #     GLM_MODEL: ${GLM_MODEL:-GLM-4.5-Air}
  #     GLM_BASE_URL: ${GLM_BASE_URL:-https://api.z.ai/api/paas/v4/}
  #     REVIEW_LANGUAGE: ${REVIEW_LANGUAGE:-zh}
  #     FASTER_WHISPER_DEVICE: ${FASTER_WHISPER_DEVICE:-cuda}
  #     FASTER_WHISPER_COMPUTE_TYPE: ${FASTER_WHISPER_COMPUTE_TYPE:-int8_float16}
  #     FASTER_WHISPER_MODEL_SIZE: ${FASTER_WHISPER_MODEL_SIZE:-large-v3-turbo}
  #     WHISPER_LANGUAGE: ${WHISPER_LANGUAGE:-zh}
  #     WHISPER_THREADS: ${WHISPER_THREADS:-4}
  #     ENABLE_CHUNKING: ${ENABLE_CHUNKING:-true}
  #     CHUNK_SIZE_MINUTES: ${CHUNK_SIZE_MINUTES:-10}
  #     CHUNK_OVERLAP_SECONDS: ${CHUNK_OVERLAP_SECONDS:-15}
  #     MAX_CONCURRENT_CHUNKS: ${MAX_CONCURRENT_CHUNKS:-4}
  #     USE_VAD_SPLIT: ${USE_VAD_SPLIT:-true}
  #     MERGE_STRATEGY: ${MERGE_STRATEGY:-lcs}
  #     LOG_LEVEL: ${LOG_LEVEL:-INFO}
  #   volumes:
  #     - ./data/runner:/app/data
  #     - ./data/uploads:/app/data/uploads
  #     - ./logs:/app/logs
  #     - runner_cache_prod:/tmp/whisper_models
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ['0']
  #             capabilities: [gpu]
  #   depends_on:
  #     - server
  #   networks:
  #     - whisper_network_prod
  #   restart: unless-stopped

  # React Frontend (Production - Static Files)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
      args:
        VITE_SUPABASE_URL: ${SUPABASE_URL}
        VITE_SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
        VITE_BACKEND_URL: ${VITE_BACKEND_URL:-/api}
    container_name: whisper_frontend_prod
    networks:
      - whisper_network_prod
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

networks:
  whisper_network_prod:
    driver: bridge

volumes:
  postgres_data_prod:
    driver: local
  runner_cache_prod:
    driver: local
